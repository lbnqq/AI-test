#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
äº‘æ¨¡å‹ä¼˜å…ˆæ›¿è¡¥ç®¡ç†å™¨
å®ç°ä¸‰å±‚fallbackç­–ç•¥ï¼šOllamaäº‘æ¨¡å‹ â†’ OpenRouter â†’ æœ¬åœ°æ¨¡å‹
"""

import os
import json
import asyncio
import aiohttp
import logging
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from enum import Enum
import time


class ModelProvider(Enum):
    """æ¨¡å‹æä¾›å•†æšä¸¾"""
    OLLAMA_CLOUD = "ollama_cloud"
    OPENROUTER = "openrouter"
    LOCAL = "local"


@dataclass
class ModelConfig:
    """æ¨¡å‹é…ç½®"""
    provider: ModelProvider
    model_name: str
    base_url: str
    api_key: Optional[str] = None
    timeout: int = 60
    max_retries: int = 2


@dataclass
class EvaluationResult:
    """è¯„ä¼°ç»“æœ"""
    success: bool
    scores: Dict[str, int]
    provider: ModelProvider
    model_name: str
    response_time: float
    error_message: Optional[str] = None


class FallbackException(Exception):
    """Fallbackè¿‡ç¨‹ä¸­çš„å¼‚å¸¸"""
    pass


class ModelUnavailableError(FallbackException):
    """æ¨¡å‹ä¸å¯ç”¨å¼‚å¸¸"""
    pass


class TimeoutError(FallbackException):
    """è¶…æ—¶å¼‚å¸¸"""
    pass


class CloudFallbackManager:
    """äº‘æ¨¡å‹ä¼˜å…ˆæ›¿è¡¥ç®¡ç†å™¨"""

    def __init__(self, config_path: Optional[str] = None):
        """
        åˆå§‹åŒ–Fallbackç®¡ç†å™¨

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨config/model_fallback.yaml
        """
        self.logger = self._setup_logger()
        self.model_mapping = self._load_model_mapping(config_path)
        self.timeout_config = self._load_timeout_config()
        self.session = None

    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger("CloudFallbackManager")
        logger.setLevel(logging.INFO)

        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)

        return logger

    def _load_model_mapping(self, config_path: Optional[str]) -> Dict[str, List[ModelConfig]]:
        """åŠ è½½æ¨¡å‹æ˜ å°„é…ç½®"""
        if config_path and os.path.exists(config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
        else:
            # ä½¿ç”¨é»˜è®¤é…ç½®
            config = self._get_default_config()

        model_mapping = {}
        for brand, models in config['model_fallback_mapping'].items():
            model_mapping[brand] = []
            for provider_config in models:
                provider = ModelProvider(provider_config['provider'])
                model_config = ModelConfig(
                    provider=provider,
                    model_name=provider_config['model_name'],
                    base_url=provider_config['base_url'],
                    api_key=provider_config.get('api_key'),
                    timeout=provider_config.get('timeout', 60)
                )
                model_mapping[brand].append(model_config)

        return model_mapping

    def _get_default_config(self) -> Dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "model_fallback_mapping": {
                "qwen": [
                    {
                        "provider": "ollama_cloud",
                        "model_name": "qwen2.5:latest",
                        "base_url": "https://api.ollama.ai",
                        "api_key": os.getenv("OLLAMA_CLOUD_API_KEY"),
                        "timeout": 60
                    },
                    {
                        "provider": "openrouter",
                        "model_name": "qwen/qwen-2.5-72b-instruct",
                        "base_url": "https://openrouter.ai/api/v1",
                        "api_key": os.getenv("OPENROUTER_API_KEY"),
                        "timeout": 90
                    },
                    {
                        "provider": "local",
                        "model_name": "qwen2.5:latest",
                        "base_url": "http://localhost:11434",
                        "timeout": 120
                    }
                ],
                "deepseek": [
                    {
                        "provider": "ollama_cloud",
                        "model_name": "deepseek-r1:70b",
                        "base_url": "https://api.ollama.ai",
                        "api_key": os.getenv("OLLAMA_CLOUD_API_KEY"),
                        "timeout": 60
                    },
                    {
                        "provider": "openrouter",
                        "model_name": "deepseek/deepseek-r1-distill-llama-70b",
                        "base_url": "https://openrouter.ai/api/v1",
                        "api_key": os.getenv("OPENROUTER_API_KEY"),
                        "timeout": 90
                    },
                    {
                        "provider": "local",
                        "model_name": "deepseek-r1:8b",
                        "base_url": "http://localhost:11434",
                        "timeout": 120
                    }
                ]
            },
            "timeout_config": {
                "ollama_cloud": 60,
                "openrouter": 90,
                "local": 120
            },
            "retry_config": {
                "max_retries": 2,
                "retry_delay": 5,
                "exponential_backoff": True
            }
        }

    def _load_timeout_config(self) -> Dict:
        """åŠ è½½è¶…æ—¶é…ç½®"""
        return self._get_default_config()['timeout_config']

    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        self.session = aiohttp.ClientSession()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        if self.session:
            await self.session.close()

    async def evaluate_with_fallback(self,
                                   model_family: str,
                                   prompt: str,
                                   context: Dict[str, Any]) -> EvaluationResult:
        """
        å¸¦fallbackçš„è¯„ä¼°è°ƒç”¨

        Args:
            model_family: æ¨¡å‹ç³»åˆ— (å¦‚ 'qwen', 'deepseek')
            prompt: è¯„ä¼°æç¤ºè¯
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯

        Returns:
            EvaluationResult: è¯„ä¼°ç»“æœ
        """
        if model_family not in self.model_mapping:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç³»åˆ—: {model_family}")

        model_configs = self.model_mapping[model_family]

        for i, model_config in enumerate(model_configs):
            try:
                self.logger.info(f"å°è¯•ä½¿ç”¨ {model_config.provider.value} æ¨¡å‹: {model_config.model_name}")

                result = await self._try_model(model_config, prompt, context)

                if result.success:
                    self.logger.info(
                        f"âœ… æˆåŠŸä½¿ç”¨ {model_config.provider.value} - {model_config.model_name} "
                        f"(å“åº”æ—¶é—´: {result.response_time:.2f}s)"
                    )
                    return result
                else:
                    self.logger.warning(
                        f"âŒ {model_config.provider.value} å¤±è´¥: {result.error_message}"
                    )

            except Exception as e:
                self.logger.warning(
                    f"âŒ {model_config.provider.value} å¼‚å¸¸: {str(e)}"
                )
                continue

        # æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥
        return EvaluationResult(
            success=False,
            scores={},
            provider=ModelProvider.LOCAL,
            model_name="none",
            response_time=0.0,
            error_message="æ‰€æœ‰æ¨¡å‹éƒ½ä¸å¯ç”¨"
        )

    async def _try_model(self,
                        model_config: ModelConfig,
                        prompt: str,
                        context: Dict[str, Any]) -> EvaluationResult:
        """
        å°è¯•ä½¿ç”¨ç‰¹å®šæ¨¡å‹è¿›è¡Œè¯„ä¼°

        Args:
            model_config: æ¨¡å‹é…ç½®
            prompt: è¯„ä¼°æç¤ºè¯
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯

        Returns:
            EvaluationResult: è¯„ä¼°ç»“æœ
        """
        start_time = time.time()

        try:
            if model_config.provider == ModelProvider.OLLAMA_CLOUD:
                result = await self._try_ollama_cloud(model_config, prompt, context)
            elif model_config.provider == ModelProvider.OPENROUTER:
                result = await self._try_openrouter(model_config, prompt, context)
            elif model_config.provider == ModelProvider.LOCAL:
                result = await self._try_local_model(model_config, prompt, context)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æä¾›å•†: {model_config.provider}")

            response_time = time.time() - start_time
            result.response_time = response_time
            return result

        except asyncio.TimeoutError:
            response_time = time.time() - start_time
            return EvaluationResult(
                success=False,
                scores={},
                provider=model_config.provider,
                model_name=model_config.model_name,
                response_time=response_time,
                error_message="è¯·æ±‚è¶…æ—¶"
            )
        except Exception as e:
            response_time = time.time() - start_time
            return EvaluationResult(
                success=False,
                scores={},
                provider=model_config.provider,
                model_name=model_config.model_name,
                response_time=response_time,
                error_message=str(e)
            )

    async def _try_ollama_cloud(self,
                               model_config: ModelConfig,
                               prompt: str,
                               context: Dict[str, Any]) -> EvaluationResult:
        """å°è¯•Ollamaäº‘æ¨¡å‹"""
        # Phase 1: å®ç°Ollamaäº‘æ¨¡å‹è°ƒç”¨
        self.logger.info(f"ğŸŒ©ï¸ è°ƒç”¨Ollamaäº‘æ¨¡å‹: {model_config.model_name}")

        # TODO: å®ç°å…·ä½“çš„Ollamaäº‘APIè°ƒç”¨
        # è¿™é‡Œå…ˆè¿”å›æ¨¡æ‹Ÿç»“æœ
        await asyncio.sleep(1)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ

        return EvaluationResult(
            success=True,
            scores={
                'openness_to_experience': 4,
                'conscientiousness': 3,
                'extraversion': 5,
                'agreeableness': 3,
                'neuroticism': 2
            },
            provider=ModelProvider.OLLAMA_CLOUD,
            model_name=model_config.model_name,
            response_time=0.0
        )

    async def _try_openrouter(self,
                             model_config: ModelConfig,
                             prompt: str,
                             context: Dict[str, Any]) -> EvaluationResult:
        """å°è¯•OpenRouteræ¨¡å‹"""
        # Phase 2: å®ç°OpenRouter APIè°ƒç”¨
        self.logger.info(f"ğŸ”— è°ƒç”¨OpenRouteræ¨¡å‹: {model_config.model_name}")

        if not model_config.api_key:
            raise ValueError("OpenRouter APIå¯†é’¥æœªé…ç½®")

        try:
            # æ„å»ºOpenRouter APIè¯·æ±‚
            headers = {
                "Authorization": f"Bearer {model_config.api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://github.com/portable-psyagent",
                "X-Title": "Big Five Personality Assessment"
            }

            # æ„å»ºè¯„ä¼°æç¤ºè¯
            evaluation_prompt = self._build_evaluation_prompt(prompt, context)

            payload = {
                "model": model_config.model_name,
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤§äº”äººæ ¼è¯„ä¼°ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„å›ç­”ï¼Œè¯„ä¼°å…¶åœ¨äº”ä¸ªç»´åº¦ä¸Šçš„å¾—åˆ†(1-5åˆ†)ã€‚"
                    },
                    {
                        "role": "user",
                        "content": evaluation_prompt
                    }
                ],
                "temperature": 0.1,
                "max_tokens": 500
            }

            # å‘é€è¯·æ±‚
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{model_config.base_url}/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=model_config.timeout)
                ) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        raise Exception(f"OpenRouter APIé”™è¯¯: {response.status} - {error_text}")

                    result_data = await response.json()

                    # è§£æå“åº”
                    scores = self._parse_openrouter_response(result_data)

                    self.logger.info(f"âœ… OpenRouterè¯„ä¼°æˆåŠŸ: {scores}")

                    return EvaluationResult(
                        success=True,
                        scores=scores,
                        provider=ModelProvider.OPENROUTER,
                        model_name=model_config.model_name,
                        response_time=0.0
                    )

        except asyncio.TimeoutError:
            raise Exception("OpenRouter APIè°ƒç”¨è¶…æ—¶")
        except Exception as e:
            self.logger.error(f"âŒ OpenRouterè°ƒç”¨å¤±è´¥: {str(e)}")
            raise Exception(f"OpenRouter APIè°ƒç”¨å¤±è´¥: {str(e)}")

    def _build_evaluation_prompt(self, prompt: str, context: Dict[str, Any]) -> str:
        """æ„å»ºè¯„ä¼°æç¤ºè¯"""
        question_id = context.get("question_id", "Unknown")
        concept = context.get("concept", "")
        is_reversed = context.get("is_reversed", False)

        evaluation_prompt = f"""
è¯·æ ¹æ®ä»¥ä¸‹å†…å®¹ï¼Œè¯„ä¼°ç”¨æˆ·çš„å¤§äº”äººæ ¼ç‰¹è´¨å¾—åˆ†(1-5åˆ†):

é¢˜ç›®ID: {question_id}
æ¦‚å¿µ: {concept}
æ˜¯å¦åå‘è®¡åˆ†: {is_reversed}
ç”¨æˆ·å›ç­”: {prompt}

è¯·ä»¥JSONæ ¼å¼è¿”å›è¯„ä¼°ç»“æœï¼ŒåŒ…å«ä»¥ä¸‹äº”ä¸ªç»´åº¦çš„å¾—åˆ†ï¼š
- openness_to_experience (å¼€æ”¾æ€§)
- conscientiousness (å°½è´£æ€§)
- extraversion (å¤–å‘æ€§)
- agreeableness (å®œäººæ€§)
- neuroticism (ç¥ç»è´¨)

æ¯ä¸ªç»´åº¦å¾—åˆ†èŒƒå›´ä¸º1-5åˆ†ï¼Œå…¶ä¸­1åˆ†è¡¨ç¤ºè¯¥ç‰¹è´¨è¡¨ç°å¾ˆå¼±ï¼Œ5åˆ†è¡¨ç¤ºè¯¥ç‰¹è´¨è¡¨ç°å¾ˆå¼ºã€‚
å¦‚æœæ˜¯åå‘è®¡åˆ†é¢˜ç›®ï¼Œè¯·ç›¸åº”è°ƒæ•´è¯„åˆ†é€»è¾‘ã€‚

è¿”å›æ ¼å¼:
{{"openness_to_experience": æ•°å€¼, "conscientiousness": æ•°å€¼, "extraversion": æ•°å€¼, "agreeableness": æ•°å€¼, "neuroticism": æ•°å€¼}}
"""
        return evaluation_prompt

    def _parse_openrouter_response(self, response_data: Dict) -> Dict[str, int]:
        """è§£æOpenRouterå“åº”"""
        try:
            content = response_data["choices"][0]["message"]["content"]

            # å°è¯•è§£æJSONå“åº”
            import json
            import re

            # æŸ¥æ‰¾JSONæ¨¡å¼
            json_match = re.search(r'\{[^}]+\}', content)
            if json_match:
                scores_json = json_match.group(0)
                scores = json.loads(scores_json)

                # éªŒè¯å¹¶æ¸…ç†åˆ†æ•°
                cleaned_scores = {}
                for dimension, score in scores.items():
                    if dimension in ['openness_to_experience', 'conscientiousness',
                                   'extraversion', 'agreeableness', 'neuroticism']:
                        try:
                            score_int = int(score)
                            if 1 <= score_int <= 5:
                                cleaned_scores[dimension] = score_int
                            else:
                                cleaned_scores[dimension] = 3  # é»˜è®¤ä¸­æ€§åˆ†
                        except (ValueError, TypeError):
                            cleaned_scores[dimension] = 3

                # ç¡®ä¿æ‰€æœ‰ç»´åº¦éƒ½æœ‰å€¼
                for dimension in ['openness_to_experience', 'conscientiousness',
                                 'extraversion', 'agreeableness', 'neuroticism']:
                    if dimension not in cleaned_scores:
                        cleaned_scores[dimension] = 3

                return cleaned_scores
            else:
                # å¦‚æœæ— æ³•è§£æJSONï¼Œè¿”å›é»˜è®¤åˆ†æ•°
                self.logger.warning("æ— æ³•è§£æOpenRouterå“åº”JSONï¼Œä½¿ç”¨é»˜è®¤åˆ†æ•°")
                return {
                    'openness_to_experience': 3,
                    'conscientiousness': 3,
                    'extraversion': 3,
                    'agreeableness': 3,
                    'neuroticism': 3
                }

        except (KeyError, IndexError, json.JSONDecodeError) as e:
            self.logger.error(f"è§£æOpenRouterå“åº”å¤±è´¥: {str(e)}")
            return {
                'openness_to_experience': 3,
                'conscientiousness': 3,
                'extraversion': 3,
                'agreeableness': 3,
                'neuroticism': 3
            }

    async def _try_local_model(self,
                              model_config: ModelConfig,
                              prompt: str,
                              context: Dict[str, Any]) -> EvaluationResult:
        """å°è¯•æœ¬åœ°æ¨¡å‹"""
        # Phase 3: å®ç°æœ¬åœ°æ¨¡å‹è°ƒç”¨
        self.logger.info(f"ğŸ  è°ƒç”¨æœ¬åœ°æ¨¡å‹: {model_config.model_name}")

        try:
            # æ„å»ºæœ¬åœ°Ollama APIè¯·æ±‚
            headers = {
                "Content-Type": "application/json"
            }

            # æ„å»ºè¯„ä¼°æç¤ºè¯
            evaluation_prompt = self._build_evaluation_prompt(prompt, context)

            payload = {
                "model": model_config.model_name,
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤§äº”äººæ ¼è¯„ä¼°ä¸“å®¶ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„å›ç­”ï¼Œè¯„ä¼°å…¶åœ¨äº”ä¸ªç»´åº¦ä¸Šçš„å¾—åˆ†(1-5åˆ†)ã€‚"
                    },
                    {
                        "role": "user",
                        "content": evaluation_prompt
                    }
                ],
                "temperature": 0.1,
                "max_tokens": 500,
                "stream": False
            }

            # å‘é€è¯·æ±‚åˆ°æœ¬åœ°OllamaæœåŠ¡
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"{model_config.base_url}/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=model_config.timeout)
                ) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        raise Exception(f"æœ¬åœ°Ollama APIé”™è¯¯: {response.status} - {error_text}")

                    result_data = await response.json()

                    # è§£æå“åº”
                    scores = self._parse_openrouter_response(result_data)  # å¤ç”¨OpenRouterçš„è§£æé€»è¾‘

                    self.logger.info(f"âœ… æœ¬åœ°Ollamaè¯„ä¼°æˆåŠŸ: {scores}")

                    return EvaluationResult(
                        success=True,
                        scores=scores,
                        provider=ModelProvider.LOCAL,
                        model_name=model_config.model_name,
                        response_time=0.0
                    )

        except asyncio.TimeoutError:
            raise Exception("æœ¬åœ°Ollama APIè°ƒç”¨è¶…æ—¶")
        except aiohttp.ClientConnectorError:
            raise Exception("æœ¬åœ°OllamaæœåŠ¡ä¸å¯è¾¾ï¼Œè¯·ç¡®è®¤æœåŠ¡å·²å¯åŠ¨")
        except Exception as e:
            self.logger.error(f"âŒ æœ¬åœ°Ollamaè°ƒç”¨å¤±è´¥: {str(e)}")
            raise Exception(f"æœ¬åœ°Ollama APIè°ƒç”¨å¤±è´¥: {str(e)}")

    async def check_local_model_availability(self, model_config: ModelConfig) -> bool:
        """æ£€æŸ¥æœ¬åœ°æ¨¡å‹å¯ç”¨æ€§"""
        try:
            headers = {"Content-Type": "application/json"}

            # ä½¿ç”¨Ollamaçš„tags APIæ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    f"{model_config.base_url}/api/tags",
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    if response.status == 200:
                        models_data = await response.json()
                        available_models = [model['name'].split(':')[0] for model in models_data.get('models', [])]
                        return model_config.model_name.split(':')[0] in available_models
                    else:
                        return False
        except Exception as e:
            self.logger.warning(f"æ£€æŸ¥æœ¬åœ°æ¨¡å‹å¯ç”¨æ€§å¤±è´¥: {str(e)}")
            return False

    def get_supported_models(self) -> List[str]:
        """è·å–æ”¯æŒçš„æ¨¡å‹ç³»åˆ—"""
        return list(self.model_mapping.keys())

    def get_fallback_chain(self, model_family: str) -> List[str]:
        """è·å–æŒ‡å®šæ¨¡å‹ç³»åˆ—çš„fallbacké“¾"""
        if model_family not in self.model_mapping:
            return []

        return [
            f"{config.provider.value}:{config.model_name}"
            for config in self.model_mapping[model_family]
        ]


# å·¥å‚å‡½æ•°
async def create_fallback_manager(config_path: Optional[str] = None) -> CloudFallbackManager:
    """åˆ›å»ºå¹¶åˆå§‹åŒ–Fallbackç®¡ç†å™¨"""
    manager = CloudFallbackManager(config_path)
    await manager.__aenter__()
    return manager