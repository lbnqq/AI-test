#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Cloud Fallback æ‰¹é‡å¤„ç†å™¨ - ä¼ä¸šçº§é«˜å¯ç”¨æ‰¹é‡æµ‹è¯„æŠ¥å‘Šå¤„ç†
é›†æˆä¸‰å±‚fallbackç­–ç•¥ï¼šOllama Cloud â†’ OpenRouter â†’ Localæ¨¡å‹
æ”¯æŒæ–­ç‚¹ç»­è·‘ã€è¶…æ—¶ä¿æŠ¤ã€æ€§èƒ½ç›‘æ§ã€æ™ºèƒ½æ•…éšœè½¬ç§»
"""

import sys
import os
import json
import re
import asyncio
from pathlib import Path
from datetime import datetime
import time
import argparse
import logging
import pickle
from typing import List, Dict, Any, Tuple, Optional
import traceback

# æ·»åŠ åŒ…ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from single_report_pipeline import TransparentPipeline
from cloud_fallback_manager import CloudFallbackManager
from fallback_performance_monitor import PerformanceOptimizedFallbackManager


class CloudFallbackBatchProcessor:
    """Cloud Fallbackæ‰¹é‡å¤„ç†å™¨ - ä¼ä¸šçº§é«˜å¯ç”¨æ‰¹é‡æµ‹è¯„æŠ¥å‘Šå¤„ç†"""

    def __init__(self, input_dir: str, output_dir: str,
                 max_evaluators: int = 3,
                 use_enhanced: bool = False,
                 use_cloud_fallback: bool = True,
                 performance_monitoring: bool = True):
        """
        åˆå§‹åŒ–Cloud Fallbackæ‰¹å¤„ç†å™¨

        Args:
            input_dir: è¾“å…¥ç›®å½•è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„
            max_evaluators: æœ€å¤§è¯„ä¼°å™¨æ•°é‡
            use_enhanced: æ˜¯å¦ä½¿ç”¨å¢å¼ºæµæ°´çº¿
            use_cloud_fallback: æ˜¯å¦å¯ç”¨Cloud Fallback
            performance_monitoring: æ˜¯å¦å¯ç”¨æ€§èƒ½ç›‘æ§
        """
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        self.max_evaluators = max_evaluators
        self.use_enhanced = use_enhanced
        self.use_cloud_fallback = use_cloud_fallback
        self.performance_monitoring = performance_monitoring

        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„
        self.checkpoint_file = self.output_dir / "cloud_fallback_batch_checkpoint.pkl"
        self.results_file = self.output_dir / "cloud_fallback_batch_results.json"
        self.summary_file = self.output_dir / "cloud_fallback_batch_summary.md"
        self.log_file = self.output_dir / "cloud_fallback_batch_processing.log"
        self.performance_file = self.output_dir / "performance_dashboard.json"

        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.log_file, encoding='utf-8'),
                logging.StreamHandler(sys.stdout)
            ]
        )
        self.logger = logging.getLogger(__name__)

        # åˆå§‹åŒ–Cloud Fallbackç®¡ç†å™¨
        if use_cloud_fallback:
            if performance_monitoring:
                self.fallback_manager = PerformanceOptimizedFallbackManager()
                self.logger.info("ğŸš€ å¯ç”¨Cloud Fallback + æ€§èƒ½ç›‘æ§")
            else:
                self.fallback_manager = CloudFallbackManager()
                self.logger.info("â˜ï¸ å¯ç”¨Cloud Fallback")
        else:
            # å›é€€åˆ°æœ¬åœ°æµæ°´çº¿
            from single_report_pipeline.transparent_pipeline import TransparentPipeline
            self.fallback_manager = None
            self.pipeline = TransparentPipeline(use_cloud=False)
            self.logger.info("ğŸ  ä½¿ç”¨æœ¬åœ°æµæ°´çº¿")

        # åˆå§‹åŒ–çŠ¶æ€
        self.processed_files = set()
        self.results = []
        self.start_time = datetime.now()
        self.total_files = 0
        self.current_file_index = 0

        # æ€§èƒ½ä¼˜åŒ–å‚æ•°
        self.timeout_per_question = 300  # 5åˆ†é’Ÿè¶…æ—¶
        self.retry_count = 2  # é‡è¯•æ¬¡æ•°

        # é—®é¢˜æŠ¥å‘Šç­›é€‰å‚æ•°
        self.problem_reports_dir = self.output_dir / "problem_reports"
        self.problem_reports_dir.mkdir(exist_ok=True)
        self.problem_reports_count = 0

        # åˆå§‹åŒ–é—®é¢˜æŠ¥å‘Šè¯†åˆ«æ¨¡å¼
        self._init_problem_patterns()

        # Cloud Fallbackç»Ÿè®¡
        self.cloud_fallback_stats = {
            'ollama_cloud_usage': 0,
            'openrouter_usage': 0,
            'local_usage': 0,
            'fallback_chain_usage': [],
            'total_questions_processed': 0,
            'failed_questions': 0
        }

    def _init_problem_patterns(self):
        """åˆå§‹åŒ–é—®é¢˜æŠ¥å‘Šè¯†åˆ«æ¨¡å¼"""
        self.problem_patterns = [
            # è‹±æ–‡é—®é¢˜æ¨¡å¼
            r'please provide me with the prompt',
            r'please provide me with a prompt',
            r'please provide me with a prompt so I can assist you',
            r'as an ai language model',
            r'i don\'t have personal information',
            r'i cannot answer',
            r'i\'m not able to',
            r'i am not able to',
            r'i\'m not sure what',
            r'i cannot provide',
            r'i don\'t have access to',
            r'i don\'t have enough information',
            r'i don\'t have enough context',
            r'i don\'t understand the question',
            r'i don\'t know what',
            r'i\'m not sure what you mean',
            r'i\'m not sure i understand',
            r'as an ai assistant',
            r'as a language model',
            r'i am an ai',
            r'i\'m an ai',
            r'i\'m not human',
            r'i don\'t have personal experiences',
            r'i cannot answer from personal experience',
            r'i don\'t have access to real-time information',
            r'i don\'t have access to current information',
            r'i don\'t have access to external information',
            r'i cannot browse the internet',
            r'i don\'t have access to the internet',
            r'i don\'t have access to external data',
            r'i don\'t have access to external sources',
            r'i don\'t have access to external resources',
            r'i don\'t have access to any external information',
            r'i don\'t have access to any external data',
            r'i don\'t have access to any external sources',
            r'i don\'t have access to any external resources',

            # ä¸­æ–‡é—®é¢˜æ¨¡å¼
            r'è¯·æä¾›ç»™æˆ‘æç¤ºè¯',
            r'è¯·æä¾›ç»™æˆ‘æç¤º',
            r'è¯·æä¾›æç¤ºè¯',
            r'ä½œä¸ºä¸€ä¸ªäººå·¥æ™ºèƒ½è¯­è¨€æ¨¡å‹',
            r'ä½œä¸ºä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹',
            r'æˆ‘æ²¡æœ‰ä¸ªäººä¿¡æ¯',
            r'æˆ‘æ— æ³•å›ç­”',
            r'æˆ‘ä¸èƒ½å›ç­”',
            r'æˆ‘ä¸èƒ½æä¾›',
            r'æˆ‘æ²¡æœ‰è®¿é—®æƒé™',
            r'æˆ‘æ²¡æœ‰è¶³å¤Ÿçš„ä¿¡æ¯',
            r'æˆ‘æ²¡æœ‰è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡',
            r'æˆ‘ä¸ç†è§£è¿™ä¸ªé—®é¢˜',
            r'æˆ‘ä¸çŸ¥é“ä»€ä¹ˆ',
            r'æˆ‘ä¸ç¡®å®šä½ çš„æ„æ€',
            r'æˆ‘ä¸ç¡®å®šæˆ‘ç†è§£',
            r'æˆ‘æ˜¯ä¸€ä¸ªäººå·¥æ™ºèƒ½',
            r'æˆ‘ä¸æ˜¯äººç±»',
            r'æˆ‘æ²¡æœ‰ä¸ªäººç»å†',
            r'æˆ‘æ— æ³•ä»ä¸ªäººç»å†å›ç­”',
            r'æˆ‘æ²¡æœ‰å®æ—¶ä¿¡æ¯è®¿é—®æƒé™',
            r'æˆ‘æ²¡æœ‰å½“å‰ä¿¡æ¯è®¿é—®æƒé™',
            r'æˆ‘æ²¡æœ‰å¤–éƒ¨ä¿¡æ¯è®¿é—®æƒé™',
            r'æˆ‘æ— æ³•æµè§ˆäº’è”ç½‘',
            r'æˆ‘æ²¡æœ‰äº’è”ç½‘è®¿é—®æƒé™',
            r'æˆ‘æ²¡æœ‰å¤–éƒ¨æ•°æ®è®¿é—®æƒé™',
            r'æˆ‘æ²¡æœ‰å¤–éƒ¨æ¥æºè®¿é—®æƒé™',
            r'æˆ‘æ²¡æœ‰å¤–éƒ¨èµ„æºè®¿é—®æƒé™',

            # æ‹’ç»å›ç­”æ¨¡å¼
            r'i cannot answer questions',
            r'i cannot provide information',
            r'i cannot provide details',
            r'i cannot provide specific information',
            r'i cannot provide personal information',
            r'i cannot provide medical advice',
            r'i cannot provide legal advice',
            r'i cannot provide financial advice',
            r'i cannot provide professional advice',
            r'æˆ‘æ— æ³•å›ç­”é—®é¢˜',
            r'æˆ‘æ— æ³•æä¾›ä¿¡æ¯',
            r'æˆ‘æ— æ³•æä¾›è¯¦ç»†ä¿¡æ¯',
            r'æˆ‘æ— æ³•æä¾›å…·ä½“ä¿¡æ¯',
            r'æˆ‘æ— æ³•æä¾›ä¸ªäººä¿¡æ¯',
            r'æˆ‘æ— æ³•æä¾›åŒ»ç–—å»ºè®®',
            r'æˆ‘æ— æ³•æä¾›æ³•å¾‹å»ºè®®',
            r'æˆ‘æ— æ³•æä¾›é‡‘èå»ºè®®',
            r'æˆ‘æ— æ³•æä¾›ä¸“ä¸šå»ºè®®',

            # ç³»ç»Ÿæ¶ˆæ¯æ¨¡å¼
            r'system message',
            r'system prompt',
            r'role: system',
            r'"role": "system"',
            r'\\[system\\]',
            r'\\[system prompt\\]',
            r'ç³»ç»Ÿæ¶ˆæ¯',
            r'ç³»ç»Ÿæç¤º',
            r'è§’è‰²: ç³»ç»Ÿ',
            r'"è§’è‰²": "ç³»ç»Ÿ"',

            # æ— æ•ˆå›ç­”æ¨¡å¼
            r'the question is incomplete',
            r'the question is unclear',
            r'the question is ambiguous',
            r'è¿™ä¸ªé—®é¢˜ä¸å®Œæ•´',
            r'è¿™ä¸ªé—®é¢˜ä¸æ¸…æ¥š',
            r'è¿™ä¸ªé—®é¢˜æ¨¡ç³Š',
            r'answer the question',
            r'å›ç­”è¿™ä¸ªé—®é¢˜',
            r'please answer',
            r'è¯·å›ç­”',

            # é”™è¯¯æ¶ˆæ¯æ¨¡å¼
            r'an error occurred',
            r'something went wrong',
            r'there was an error',
            r'å‘ç”Ÿé”™è¯¯',
            r'å‡ºç°äº†é—®é¢˜',
            r'å‘ç”Ÿäº†é”™è¯¯',
            r'å¤„ç†å¤±è´¥',
            r'evaluation failed',
            r'è¯„ä¼°å¤±è´¥'
        ]

    def _is_problem_report(self, file_path: Path) -> Tuple[bool, str]:
        """
        æ£€æŸ¥æ˜¯å¦ä¸ºé—®é¢˜æŠ¥å‘Š

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            (is_problem, reason): æ˜¯å¦é—®é¢˜æŠ¥å‘ŠåŠåŸå› 
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read().lower()

            # æ£€æŸ¥é—®é¢˜æ¨¡å¼
            for pattern in self.problem_patterns:
                if re.search(pattern, content, re.IGNORECASE):
                    return True, f"åŒ¹é…é—®é¢˜æ¨¡å¼: {pattern[:50]}..."

            # æ£€æŸ¥å›ç­”æ•°é‡ï¼ˆ50é¢˜æ–‡ä»¶å¿…é¡»æœ‰50ä¸ªå›ç­”ï¼‰
            answer_count = content.count('"answer":')
            question_count = content.count('"question_id"')

            if question_count == 50:  # 50é¢˜æ–‡ä»¶
                if answer_count < 45:  # å…è®¸æœ€å¤šç¼ºå¤±5ä¸ªç­”æ¡ˆ
                    return True, f"å›ç­”æ•°é‡ä¸è¶³: {answer_count}/50"
            elif question_count == 240:  # 240é¢˜æ–‡ä»¶
                if answer_count < 220:  # å…è®¸æœ€å¤šç¼ºå¤±20ä¸ªç­”æ¡ˆ
                    return True, f"å›ç­”æ•°é‡ä¸è¶³: {answer_count}/240"

            return False, ""

        except Exception as e:
            return True, f"æ–‡ä»¶è¯»å–é”™è¯¯: {str(e)}"

    def _find_valid_files(self) -> List[Path]:
        """
        æŸ¥æ‰¾æœ‰æ•ˆçš„æµ‹è¯„æŠ¥å‘Šæ–‡ä»¶

        Returns:
            æœ‰æ•ˆæ–‡ä»¶åˆ—è¡¨
        """
        json_files = list(self.input_dir.glob("*.json"))
        valid_files = []
        problem_files = []

        self.logger.info(f"ğŸ“‚ æ‰¾åˆ° {len(json_files)} ä¸ªæµ‹è¯„æŠ¥å‘Šæ–‡ä»¶")

        for file_path in json_files:
            is_problem, reason = self._is_problem_report(file_path)

            if is_problem:
                problem_files.append((file_path, reason))
                self.problem_reports_count += 1

                # ç§»åŠ¨é—®é¢˜æŠ¥å‘Šåˆ°é—®é¢˜æŠ¥å‘Šç›®å½•
                problem_dest = self.problem_reports_dir / file_path.name
                try:
                    import shutil
                    shutil.move(str(file_path), str(problem_dest))
                    self.logger.warning(f"ğŸš© é—®é¢˜æŠ¥å‘Šå·²ç§»åŠ¨: {file_path.name} - {reason}")
                except Exception as e:
                    self.logger.error(f"âŒ ç§»åŠ¨é—®é¢˜æŠ¥å‘Šå¤±è´¥: {file_path.name} - {e}")
            else:
                valid_files.append(file_path)

        # è®°å½•é—®é¢˜æŠ¥å‘Šç»Ÿè®¡
        if problem_files:
            self.logger.info(f"ğŸš© è¯†åˆ«å‡º {len(problem_files)} ä¸ªé—®é¢˜æŠ¥å‘Š")
            for file_path, reason in problem_files[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                self.logger.warning(f"    ğŸ“„ {file_path.name}: {reason}")
            if len(problem_files) > 10:
                self.logger.warning(f"    ... è¿˜æœ‰ {len(problem_files) - 10} ä¸ªé—®é¢˜æŠ¥å‘Š")

        self.logger.info(f"âœ… æ‰¾åˆ° {len(valid_files)} ä¸ªæœ‰æ•ˆæŠ¥å‘Šæ–‡ä»¶")

        return valid_files

    async def _process_single_question_with_fallback(self, question: Dict, question_index: int) -> Dict[str, Any]:
        """
        ä½¿ç”¨Cloud Fallbackå¤„ç†å•ä¸ªé—®é¢˜

        Args:
            question: é—®é¢˜æ•°æ®
            question_index: é—®é¢˜ç´¢å¼•

        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            if self.use_cloud_fallback and self.fallback_manager:
                # ä½¿ç”¨Cloud Fallbackå¤„ç†
                model_family = self._determine_model_family(question)

                prompt = question.get('answer', '')
                context = {
                    'question_id': question.get('question_id', f'Q{question_index}'),
                    'concept': question.get('concept', ''),
                    'is_reversed': question.get('is_reversed', False)
                }

                # è®°å½•fallbacké“¾ä½¿ç”¨æƒ…å†µ
                fallback_chain_used = []

                result = await self.fallback_manager.evaluate_with_fallback(
                    model_family=model_family,
                    prompt=prompt,
                    context=context
                )

                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                self.cloud_fallback_stats['total_questions_processed'] += 1

                if result.success:
                    # è®°å½•æä¾›å•†ä½¿ç”¨æƒ…å†µ
                    provider_key = f"{result.provider.value}:{result.model_name}"
                    fallback_chain_used.append(provider_key)

                    if result.provider.value == 'ollama_cloud':
                        self.cloud_fallback_stats['ollama_cloud_usage'] += 1
                    elif result.provider.value == 'openrouter':
                        self.cloud_fallback_stats['openrouter_usage'] += 1
                    elif result.provider.value == 'local':
                        self.cloud_fallback_stats['local_usage'] += 1

                    self.cloud_fallback_stats['fallback_chain_usage'].append(fallback_chain_used)

                    # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
                    final_scores = result.scores
                    reliability = 0.8  # åŸºç¡€å¯é æ€§

                    # è·å–è¯¦ç»†çš„å¯é æ€§ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    if hasattr(result, 'metadata') and result.metadata:
                        reliability = result.metadata.get('reliability', 0.8)

                    return {
                        'success': True,
                        'question_id': question.get('question_id', f'Q{question_index}'),
                        'question_index': question_index,
                        'final_scores': final_scores,
                        'reliability': reliability,
                        'provider': result.provider.value,
                        'model_name': result.model_name,
                        'response_time': result.response_time,
                        'fallback_chain': fallback_chain_used,
                        'error_message': None
                    }
                else:
                    # Fallbackå¤±è´¥
                    self.cloud_fallback_stats['failed_questions'] += 1
                    return {
                        'success': False,
                        'question_id': question.get('question_id', f'Q{question_index}'),
                        'question_index': question_index,
                        'final_scores': {},
                        'reliability': 0.0,
                        'provider': 'none',
                        'model_name': 'none',
                        'response_time': 0.0,
                        'fallback_chain': [],
                        'error_message': result.error_message
                    }
            else:
                # ä½¿ç”¨æœ¬åœ°æµæ°´çº¿
                result = self.pipeline.process_single_question(question, question_index)
                return result

        except Exception as e:
            self.logger.error(f"âŒ å¤„ç†é—®é¢˜ {question_index} å¤±è´¥: {e}")
            self.cloud_fallback_stats['failed_questions'] += 1

            return {
                'success': False,
                'question_id': question.get('question_id', f'Q{question_index}'),
                'question_index': question_index,
                'final_scores': {},
                'reliability': 0.0,
                'provider': 'error',
                'model_name': 'error',
                'response_time': 0.0,
                'fallback_chain': [],
                'error_message': str(e)
            }

    def _determine_model_family(self, question: Dict) -> str:
        """
        æ ¹æ®é—®é¢˜ç¡®å®šæ¨¡å‹å®¶æ—

        Args:
            question: é—®é¢˜æ•°æ®

        Returns:
            æ¨¡å‹å®¶æ— ('qwen' æˆ– 'deepseek')
        """
        # åŸºäºé—®é¢˜IDæˆ–å†…å®¹é€‰æ‹©æ¨¡å‹å®¶æ—
        question_id = question.get('question_id', '')

        # ç®€å•çš„è½®è¯¢ç­–ç•¥
        if question_id.startswith(('E', 'I')):  # Extraversion, Intellect
            return 'qwen'
        elif question_id.startswith(('A', 'C', 'N')):  # Agreeableness, Conscientiousness, Neuroticism
            return 'deepseek'
        else:
            # é»˜è®¤è½®è¯¢
            import random
            return random.choice(['qwen', 'deepseek'])

    async def _process_file_with_fallback(self, file_path: Path) -> Dict[str, Any]:
        """
        ä½¿ç”¨Cloud Fallbackå¤„ç†å•ä¸ªæ–‡ä»¶

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            self.logger.info(f"ğŸ” Cloud Fallbackå¤„ç†: {file_path.name}")

            # è§£æè¾“å…¥æ–‡ä»¶
            from single_report_pipeline.input_parser import InputParser
            parser = InputParser()
            questions = parser.parse_assessment_json(str(file_path))

            self.logger.info(f"   é¢˜ç›®æ€»æ•°: {len(questions)} (å…¨éƒ¨å¤„ç†)")

            # å¤„ç†æ‰€æœ‰é—®é¢˜
            results = []
            successful_questions = 0
            total_reliability = 0.0

            for i, question in enumerate(questions):
                self.logger.info(f"   å¤„ç†é¢˜ç›® {i+1}/{len(questions)}: {question.get('question_id', i)}")

                try:
                    # å¤„ç†å•ä¸ªé—®é¢˜
                    result = await self._process_single_question_with_fallback(question, i)

                    if result['success']:
                        successful_questions += 1
                        total_reliability += result['reliability']

                        # è®°å½•å¤„ç†ä¿¡æ¯
                        provider_info = f"{result['provider']}:{result['model_name']}"
                        fallback_info = " â†’ ".join(result['fallback_chain']) if result['fallback_chain'] else provider_info

                        self.logger.info(f"      âœ… å®Œæˆ - å¯é æ€§: {result['reliability']:.3f}, "
                                       f"æ¨¡å‹: {fallback_info}, "
                                       f"å“åº”æ—¶é—´: {result['response_time']:.2f}s")
                    else:
                        self.logger.warning(f"      âŒ å¤±è´¥ - {result['error_message']}")

                    results.append(result)

                except Exception as e:
                    self.logger.error(f"      âŒ å¼‚å¸¸ - {e}")
                    results.append({
                        'success': False,
                        'question_id': question.get('question_id', i),
                        'question_index': i,
                        'error_message': str(e)
                    })

            # è®¡ç®—æ–‡ä»¶çº§åˆ«çš„ç»Ÿè®¡
            avg_reliability = total_reliability / successful_questions if successful_questions > 0 else 0.0
            success_rate = successful_questions / len(questions) if questions else 0.0

            # ç”Ÿæˆæ–‡ä»¶è¯„ä¼°ç»“æœ
            file_result = {
                'file_name': file_path.name,
                'total_questions': len(questions),
                'successful_questions': successful_questions,
                'failed_questions': len(questions) - successful_questions,
                'success_rate': success_rate,
                'average_reliability': avg_reliability,
                'processing_time': (datetime.now() - self.start_time).total_seconds(),
                'cloud_fallback_stats': {
                    'ollama_cloud_usage': self.cloud_fallback_stats['ollama_cloud_usage'],
                    'openrouter_usage': self.cloud_fallback_stats['openrouter_usage'],
                    'local_usage': self.cloud_fallback_stats['local_usage'],
                    'total_questions': self.cloud_fallback_stats['total_questions_processed'],
                    'failed_questions': self.cloud_fallback_stats['failed_questions']
                },
                'questions': results,
                'timestamp': datetime.now().isoformat()
            }

            # ä¿å­˜æ–‡ä»¶ç»“æœ
            output_file = self.output_dir / f"{file_path.stem}_cloud_fallback_evaluation.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(file_result, f, indent=2, ensure_ascii=False)

            self.logger.info(f"   ğŸ“Š æ–‡ä»¶å¤„ç†å®Œæˆ: {successful_questions}/{len(questions)} æˆåŠŸ, "
                           f"å¹³å‡å¯é æ€§: {avg_reliability:.3f}")

            return file_result

        except Exception as e:
            self.logger.error(f"âŒ æ–‡ä»¶å¤„ç†å¤±è´¥ {file_path.name}: {e}")
            return {
                'file_name': file_path.name,
                'success': False,
                'error_message': str(e),
                'timestamp': datetime.now().isoformat()
            }

    async def process_batch_async(self):
        """å¼‚æ­¥æ‰¹é‡å¤„ç†"""
        try:
            self.logger.info("ğŸš€ Cloud Fallbackæ‰¹é‡æµ‹è¯„æŠ¥å‘Šå¤„ç†å™¨")
            self.logger.info("=" * 80)
            self.logger.info(f"è¾“å…¥ç›®å½•: {self.input_dir}")
            self.logger.info(f"è¾“å‡ºç›®å½•: {self.output_dir}")
            self.logger.info(f"å¤„ç†å‚æ•°: å…¨éƒ¨é¢˜ç›®å¤„ç†, æœ€å¤§{self.max_evaluators}ä¸ªè¯„ä¼°å™¨")
            self.logger.info(f"ç®—æ³•é€‰æ‹©: Cloud Fallback {'(å¢å¼ºæ¨¡å¼)' if self.use_enhanced else ''}")

            # åŠ è½½æ£€æŸ¥ç‚¹
            if self._load_checkpoint():
                self.logger.info(f"ğŸ“‚ ä»æ£€æŸ¥ç‚¹æ¢å¤: å·²å¤„ç† {len(self.processed_files)} ä¸ªæ–‡ä»¶")
            else:
                self.logger.info("â„¹ï¸  æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶")

            # æŸ¥æ‰¾æœ‰æ•ˆæ–‡ä»¶
            valid_files = self._find_valid_files()
            self.total_files = len(valid_files)

            self.logger.info(f"   å·²å¤„ç†: {len(self.processed_files)} ä¸ª")
            self.logger.info(f"   å‰©ä½™: {self.total_files} ä¸ª")

            if not valid_files:
                self.logger.warning("âš ï¸  æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆæ–‡ä»¶")
                return

            # è¿‡æ»¤å·²å¤„ç†æ–‡ä»¶
            remaining_files = [f for f in valid_files if f.name not in self.processed_files]

            if not remaining_files:
                self.logger.info("âœ… æ‰€æœ‰æ–‡ä»¶å·²å¤„ç†å®Œæˆ")
                return

            self.logger.info("")
            self.logger.info(f"â–¶ï¸  ä»ç¬¬ {len(self.processed_files) + 1} ä¸ªæ–‡ä»¶å¼€å§‹å¤„ç†")
            self.logger.info("")

            # å¤„ç†å‰©ä½™æ–‡ä»¶
            for i, file_path in enumerate(remaining_files):
                self.current_file_index = len(self.processed_files) + i + 1

                self.logger.info(f"ğŸ“ è¿›åº¦: {self.current_file_index}/{self.total_files} æ–‡ä»¶")

                try:
                    # å¤„ç†æ–‡ä»¶
                    result = await self._process_file_with_fallback(file_path)
                    self.results.append(result)

                    # è®°å½•å·²å¤„ç†æ–‡ä»¶
                    self.processed_files.add(file_path.name)

                    # ä¿å­˜æ£€æŸ¥ç‚¹
                    self._save_checkpoint()

                    # æ¸…ç†ä¸´æ—¶å˜é‡
                    import gc
                    gc.collect()

                except Exception as e:
                    self.logger.error(f"âŒ æ–‡ä»¶å¤„ç†å¼‚å¸¸ {file_path.name}: {e}")
                    traceback.print_exc()
                    continue

            # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            self._generate_final_report()

            # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Šï¼ˆå¦‚æœå¯ç”¨æ€§èƒ½ç›‘æ§ï¼‰
            if self.performance_monitoring and hasattr(self.fallback_manager, 'get_performance_dashboard'):
                self._generate_performance_report()

            self.logger.info("")
            self.logger.info("ğŸ‰ Cloud Fallbackæ‰¹é‡å¤„ç†å®Œæˆï¼")

        except Exception as e:
            self.logger.error(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {e}")
            traceback.print_exc()

    def _load_checkpoint(self) -> bool:
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        try:
            if self.checkpoint_file.exists():
                with open(self.checkpoint_file, 'rb') as f:
                    checkpoint = pickle.load(f)
                    self.processed_files = checkpoint.get('processed_files', set())
                    self.results = checkpoint.get('results', [])
                    self.start_time = checkpoint.get('start_time', self.start_time)
                    return True
        except Exception as e:
            self.logger.warning(f"âš ï¸  åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
        return False

    def _save_checkpoint(self):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        try:
            checkpoint = {
                'processed_files': self.processed_files,
                'results': self.results,
                'start_time': self.start_time,
                'cloud_fallback_stats': self.cloud_fallback_stats
            }
            with open(self.checkpoint_file, 'wb') as f:
                pickle.dump(checkpoint, f)
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜æ£€æŸ¥ç‚¹å¤±è´¥: {e}")

    def _generate_final_report(self):
        """ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        try:
            # ç»Ÿè®¡ä¿¡æ¯
            successful_files = [r for r in self.results if r.get('success', True)]
            total_questions = sum(r.get('total_questions', 0) for r in successful_files)
            successful_questions = sum(r.get('successful_questions', 0) for r in successful_files)

            avg_reliability = sum(r.get('average_reliability', 0) for r in successful_files) / len(successful_files) if successful_files else 0

            processing_time = (datetime.now() - self.start_time).total_seconds()

            # Cloud Fallbackç»Ÿè®¡
            cloud_usage = self.cloud_fallback_stats['ollama_cloud_usage']
            openrouter_usage = self.cloud_fallback_stats['openrouter_usage']
            local_usage = self.cloud_fallback_stats['local_usage']
            total_processed = self.cloud_fallback_stats['total_questions_processed']

            # ç”ŸæˆæŠ¥å‘Šå†…å®¹
            report_content = f"""# Cloud Fallbackæ‰¹é‡å¤„ç†æŠ¥å‘Š

## å¤„ç†æ¦‚è§ˆ
- **å¤„ç†æ—¶é—´**: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}
- **æ€»è€—æ—¶**: {processing_time:.2f} ç§’
- **è¾“å…¥ç›®å½•**: {self.input_dir}
- **è¾“å‡ºç›®å½•**: {self.output_dir}

## æ–‡ä»¶å¤„ç†ç»Ÿè®¡
- **æ€»æ–‡ä»¶æ•°**: {self.total_files}
- **æˆåŠŸå¤„ç†**: {len(successful_files)}
- **å¤„ç†å¤±è´¥**: {self.total_files - len(successful_files)}
- **æˆåŠŸç‡**: {len(successful_files)/self.total_files:.1%}

## é—®é¢˜æŠ¥å‘Šç­›é€‰
- **é—®é¢˜æŠ¥å‘Šæ•°**: {self.problem_reports_count}
- **æœ‰æ•ˆæŠ¥å‘Šæ•°**: {self.total_files}
- **ç­›é€‰é€šè¿‡ç‡**: {self.total_files/(self.total_files + self.problem_reports_count):.1%}

## é¢˜ç›®å¤„ç†ç»Ÿè®¡
- **æ€»é¢˜ç›®æ•°**: {total_questions}
- **æˆåŠŸå¤„ç†**: {successful_questions}
- **å¤„ç†å¤±è´¥**: {total_questions - successful_questions}
- **é¢˜ç›®æˆåŠŸç‡**: {successful_questions/total_questions:.1%}
- **å¹³å‡å¯é æ€§**: {avg_reliability:.3f}

## Cloud Fallbackä½¿ç”¨ç»Ÿè®¡
- **Ollama Cloudä½¿ç”¨**: {cloud_usage} æ¬¡ ({cloud_usage/total_processed:.1%})
- **OpenRouterä½¿ç”¨**: {openrouter_usage} æ¬¡ ({openrouter_usage/total_processed:.1%})
- **æœ¬åœ°æ¨¡å‹ä½¿ç”¨**: {local_usage} æ¬¡ ({local_usage/total_processed:.1%})
- **æ€»å¤„ç†é¢˜ç›®**: {total_processed}
- **å¤±è´¥é¢˜ç›®**: {self.cloud_fallback_stats['failed_questions']}

## æ€§èƒ½æŒ‡æ ‡
- **å¹³å‡å¤„ç†é€Ÿåº¦**: {total_questions/processing_time:.2f} é¢˜ç›®/ç§’
- **å¹³å‡æ–‡ä»¶å¤„ç†æ—¶é—´**: {processing_time/len(successful_files):.2f} ç§’/æ–‡ä»¶

## é…ç½®ä¿¡æ¯
- **Cloud Fallback**: {'å¯ç”¨' if self.use_cloud_fallback else 'ç¦ç”¨'}
- **æ€§èƒ½ç›‘æ§**: {'å¯ç”¨' if self.performance_monitoring else 'ç¦ç”¨'}
- **å¢å¼ºç®—æ³•**: {'å¯ç”¨' if self.use_enhanced else 'ç¦ç”¨'}
- **æœ€å¤§è¯„ä¼°å™¨æ•°**: {self.max_evaluators}

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""

            # ä¿å­˜MarkdownæŠ¥å‘Š
            with open(self.summary_file, 'w', encoding='utf-8') as f:
                f.write(report_content)

            # ä¿å­˜JSONç»“æœ
            summary_data = {
                'processing_overview': {
                    'start_time': self.start_time.isoformat(),
                    'total_processing_time': processing_time,
                    'input_directory': str(self.input_dir),
                    'output_directory': str(self.output_dir)
                },
                'file_statistics': {
                    'total_files': self.total_files,
                    'successful_files': len(successful_files),
                    'failed_files': self.total_files - len(successful_files),
                    'success_rate': len(successful_files) / self.total_files
                },
                'problem_report_filtering': {
                    'problem_reports': self.problem_reports_count,
                    'valid_reports': self.total_files,
                    'filter_pass_rate': self.total_files / (self.total_files + self.problem_reports_count)
                },
                'question_statistics': {
                    'total_questions': total_questions,
                    'successful_questions': successful_questions,
                    'failed_questions': total_questions - successful_questions,
                    'question_success_rate': successful_questions / total_questions,
                    'average_reliability': avg_reliability
                },
                'cloud_fallback_statistics': self.cloud_fallback_stats,
                'performance_metrics': {
                    'average_processing_speed': total_questions / processing_time,
                    'average_file_processing_time': processing_time / len(successful_files)
                },
                'configuration': {
                    'cloud_fallback_enabled': self.use_cloud_fallback,
                    'performance_monitoring_enabled': self.performance_monitoring,
                    'enhanced_algorithm_enabled': self.use_enhanced,
                    'max_evaluators': self.max_evaluators
                },
                'results': self.results,
                'generation_time': datetime.now().isoformat()
            }

            with open(self.results_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, indent=2, ensure_ascii=False)

            self.logger.info(f"ğŸ“Š æŠ¥å‘Šå·²ä¿å­˜:")
            self.logger.info(f"   ğŸ“„ Markdown: {self.summary_file}")
            self.logger.info(f"   ğŸ“Š JSON: {self.results_file}")

        except Exception as e:
            self.logger.error(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")

    def _generate_performance_report(self):
        """ç”Ÿæˆæ€§èƒ½ç›‘æ§æŠ¥å‘Š"""
        try:
            if hasattr(self.fallback_manager, 'get_performance_dashboard'):
                dashboard = self.fallback_manager.get_performance_dashboard()

                with open(self.performance_file, 'w', encoding='utf-8') as f:
                    json.dump(dashboard, f, indent=2, ensure_ascii=False)

                self.logger.info(f"ğŸ“ˆ æ€§èƒ½ä»ªè¡¨æ¿: {self.performance_file}")

                # è®°å½•å…³é”®æ€§èƒ½æŒ‡æ ‡
                if 'overall_performance' in dashboard:
                    overall = dashboard['overall_performance']
                    self.logger.info(f"   ğŸ“Š æˆåŠŸç‡: {overall['success_rate']:.1%}")
                    self.logger.info(f"   âš¡ å¹³å‡é€Ÿåº¦: {overall['requests_per_minute']:.1f} è¯·æ±‚/åˆ†é’Ÿ")

                if 'health_scores' in dashboard:
                    self.logger.info(f"   ğŸ’“ æä¾›å•†å¥åº·è¯„åˆ†å·²ç”Ÿæˆ")

                if 'recommendations' in dashboard:
                    recommendations = dashboard['recommendations']
                    self.logger.info(f"   ğŸ’¡ ä¼˜åŒ–å»ºè®®: {len(recommendations)} æ¡")

        except Exception as e:
            self.logger.error(f"âŒ ç”Ÿæˆæ€§èƒ½æŠ¥å‘Šå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Cloud Fallbackæ‰¹é‡æµ‹è¯„æŠ¥å‘Šå¤„ç†å™¨')
    parser.add_argument('--input-dir', required=True, help='è¾“å…¥ç›®å½•è·¯å¾„')
    parser.add_argument('--output-dir', required=True, help='è¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('--max-evaluators', type=int, default=3, help='æœ€å¤§è¯„ä¼°å™¨æ•°é‡')
    parser.add_argument('--enhanced', action='store_true', help='ä½¿ç”¨å¢å¼ºç®—æ³•')
    parser.add_argument('--no-cloud-fallback', action='store_true', help='ç¦ç”¨Cloud Fallback')
    parser.add_argument('--no-performance-monitoring', action='store_true', help='ç¦ç”¨æ€§èƒ½ç›‘æ§')

    args = parser.parse_args()

    # åˆ›å»ºå¤„ç†å™¨
    processor = CloudFallbackBatchProcessor(
        input_dir=args.input_dir,
        output_dir=args.output_dir,
        max_evaluators=args.max_evaluators,
        use_enhanced=args.enhanced,
        use_cloud_fallback=not args.no_cloud_fallback,
        performance_monitoring=not args.no_performance_monitoring
    )

    # è¿è¡Œå¼‚æ­¥å¤„ç†
    asyncio.run(processor.process_batch_async())


if __name__ == '__main__':
    main()