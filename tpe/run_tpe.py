#!/usr/bin/env python
"""
Main entry point for the Targeted Pressure Executor (TPE).
"""
import argparse
import sys
import os
import json
from datetime import datetime

# Add the project root to the path so we can import services
sys.path.insert(0, os.path.dirname(__file__))

from services.role_loader import load_role_prompt
from services.plan_parser import PlanParser
from services.llm_client import LLMClient
from services.test_executor import TestExecutor

def save_results(results: list, tested_model: str, role_applied: str, source_plan_file: str, logs_dir: str = "logs"):
    """
    Saves the execution results to a structured JSON file.

    Args:
        results (list): The list of results from TestExecutor.
        tested_model (str): The model identifier used.
        role_applied (str): The role name applied.
        source_plan_file (str): The path to the source plan file.
        logs_dir (str): The directory to save the log file. Defaults to "logs".
    """
    # Ensure logs directory exists
    os.makedirs(logs_dir, exist_ok=True)
    
    # Generate filename based on TPE-NFR-04
    # Sanitize model name for use in filename
    sanitized_model_name = tested_model.replace('/', '_').replace(':', '_')
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"tpe_log_{sanitized_model_name}_{role_applied}_{timestamp}.json"
    filepath = os.path.join(logs_dir, filename)
    
    # Build the final log structure
    log_data = {
        "tested_model": tested_model,
        "role_applied": role_applied,
        "source_plan_file": source_plan_file,
        "execution_results": results
    }
    
    # Write to file
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(log_data, f, ensure_ascii=False, indent=2)
    
    print(f"Results saved to: {filepath}")

def main():
    """Main function for TPE."""
    parser = argparse.ArgumentParser(
        description='Execute a targeted pressure test plan generated by generate_pressure_plan.py'
    )
    parser.add_argument(
        '--model_name', 
        type=str, 
        required=True,
        help='Model identifier (e.g., ollama/gemma3:latest)'
    )
    parser.add_argument(
        '--role_name', 
        type=str, 
        required=True,
        help='Role name (e.g., a1, b2)'
    )
    parser.add_argument(
        '--plan_file', 
        type=str, 
        required=True,
        help='Path to the Markdown plan file'
    )
    
    args = parser.parse_args()
    
    print(f"Starting TPE with model '{args.model_name}', role '{args.role_name}', plan '{args.plan_file}'")
    
    # --- T-1.3 Integration Steps ---
    
    # 2. Load role
    print("Loading role prompt...")
    system_prompt = load_role_prompt(args.role_name)
    print(f"Role prompt loaded (length: {len(system_prompt)} chars).")
    
    # 3. Parse plan
    print("Parsing plan file...")
    parser_instance = PlanParser(args.plan_file)
    test_cases = parser_instance.parse()
    print(f"Plan parsed successfully. Found {len(test_cases)} test cases.")
    
    # 4. Execute tests
    print("Executing test plan...")
    # Use default Ollama settings
    client = LLMClient() 
    executor = TestExecutor(client, args.model_name, system_prompt)
    execution_results = executor.execute_plan(test_cases)
    print("Test plan execution completed.")
    
    # 5. Save results (using our new save_results function)
    print("Saving results...")
    save_results(execution_results, args.model_name, args.role_name, args.plan_file)
    print("TPE run completed successfully!")

if __name__ == "__main__":
    main()