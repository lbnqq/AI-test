#!/usr/bin/env python3
"""
ç®€å•æ³•å¾‹çŸ¥è¯†æµ‹è¯•è„šæœ¬
ä½¿ç”¨æœ¬åœ°æ¨¡å‹æµ‹è¯•æ³•å¾‹çŸ¥è¯†é—®ç­”èƒ½åŠ›
"""

import json
import requests

def test_legal_knowledge_ollama(model_name="qwen2.5:14b-instruct"):
    """ä½¿ç”¨Ollamaæµ‹è¯•æ³•å¾‹çŸ¥è¯†"""
    print(f"ğŸ” ä½¿ç”¨æ¨¡å‹ {model_name} è¿›è¡Œæ³•å¾‹çŸ¥è¯†æµ‹è¯•...")

    # æ³•å¾‹çŸ¥è¯†æµ‹è¯•é—®é¢˜é›†
    legal_questions = [
        {
            "question": "è¯·ç®€è¦è§£é‡Šä»€ä¹ˆæ˜¯åˆåŒæ³•ï¼Ÿ",
            "expected_keywords": ["åˆåŒ", "åè®®", "æ³•å¾‹", "æƒåˆ©ä¹‰åŠ¡"]
        },
        {
            "question": "ä»€ä¹ˆæ˜¯ä¾µæƒè¡Œä¸ºï¼Ÿè¯·ä¸¾ä¾‹è¯´æ˜ã€‚",
            "expected_keywords": ["ä¾µæƒ", "æŸå®³", "è´£ä»»", "èµ”å¿"]
        },
        {
            "question": "åˆ‘æ³•å’Œæ°‘æ³•çš„ä¸»è¦åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ",
            "expected_keywords": ["åˆ‘æ³•", "æ°‘æ³•", "çŠ¯ç½ª", "æ°‘äº‹", "åˆ‘ç½š"]
        },
        {
            "question": "ä»€ä¹ˆæ˜¯çŸ¥è¯†äº§æƒï¼ŸåŒ…æ‹¬å“ªäº›ç±»å‹ï¼Ÿ",
            "expected_keywords": ["çŸ¥è¯†äº§æƒ", "ä¸“åˆ©", "å•†æ ‡", "è‘—ä½œæƒ"]
        },
        {
            "question": "è¯·è§£é‡Šä»€ä¹ˆæ˜¯æ­£å½“é˜²å«ã€‚",
            "expected_keywords": ["æ­£å½“é˜²å«", "ä¸æ³•ä¾µå®³", "ä¿æŠ¤", "åˆç†"]
        }
    ]

    # Ollama APIé…ç½®
    ollama_url = "http://localhost:11434/api/generate"

    total_score = 0
    max_score = len(legal_questions)

    print("\n" + "="*60)
    print("ğŸ“š æ³•å¾‹çŸ¥è¯†é—®ç­”æµ‹è¯•")
    print("="*60)

    for i, q in enumerate(legal_questions, 1):
        print(f"\né—®é¢˜ {i}: {q['question']}")
        print("-" * 50)

        # å‡†å¤‡è¯·æ±‚
        payload = {
            "model": model_name,
            "prompt": q['question'],
            "stream": False,
            "options": {
                "temperature": 0.1,
                "max_tokens": 300
            }
        }

        try:
            # å‘é€è¯·æ±‚
            response = requests.post(ollama_url, json=payload, timeout=30)

            if response.status_code == 200:
                result = response.json()
                answer = result.get('response', '').strip()

                print(f"å›ç­”: {answer}")

                # ç®€å•è¯„ä¼°ç­”æ¡ˆè´¨é‡
                score = evaluate_answer(answer, q['expected_keywords'])
                total_score += score
                print(f"è¯„åˆ†: {score}/2 â­" if score > 0 else "è¯„åˆ†: 0/2 âŒ")

            else:
                print(f"âŒ è¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
                print(f"é”™è¯¯ä¿¡æ¯: {response.text}")

        except requests.exceptions.Timeout:
            print("âŒ è¯·æ±‚è¶…æ—¶")
        except requests.exceptions.ConnectionError:
            print("âŒ è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦è¿è¡Œ")
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")

        print("\n" + "-"*50)

    # æ˜¾ç¤ºæ€»ä½“ç»“æœ
    print(f"\nğŸ¯ æµ‹è¯•å®Œæˆï¼")
    print(f"æ€»å¾—åˆ†: {total_score}/{max_score}")
    print(f"æ­£ç¡®ç‡: {total_score/max_score*100:.1f}%")

    if total_score >= max_score * 0.8:
        print("âœ… æ¨¡å‹è¡¨ç°ä¼˜ç§€ï¼Œé€‚åˆæ³•å¾‹çŸ¥è¯†æµ‹è¯•ï¼")
    elif total_score >= max_score * 0.6:
        print("âœ… æ¨¡å‹è¡¨ç°è‰¯å¥½ï¼Œå¯ç”¨äºåŸºç¡€æ³•å¾‹çŸ¥è¯†æµ‹è¯•")
    else:
        print("âŒ æ¨¡å‹éœ€è¦æ”¹è¿›ï¼Œå»ºè®®ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹")

    return total_score, max_score

def evaluate_answer(answer, keywords):
    """è¯„ä¼°ç­”æ¡ˆè´¨é‡"""
    if not answer:
        return 0

    answer_lower = answer.lower()
    found_keywords = sum(1 for kw in keywords if kw.lower() in answer_lower)

    if found_keywords >= 3:
        return 2  # ä¼˜ç§€
    elif found_keywords >= 2:
        return 1  # è‰¯å¥½
    else:
        return 0  # éœ€è¦æ”¹è¿›

def get_model_info(model_name):
    """è·å–æ¨¡å‹ä¿¡æ¯"""
    try:
        response = requests.get("http://localhost:11434/api/tags")
        if response.status_code == 200:
            data = response.json()
            for model in data.get('models', []):
                if model.get('name') == model_name:
                    size = model.get('size', 0)
                    size_gb = size / (1024**3) if size else 0
                    return {
                        'name': model_name,
                        'size_gb': size_gb,
                        'available': True
                    }
        return {'available': False}
    except:
        return {'available': False}

if __name__ == "__main__":
    # æ¨èæ¨¡å‹åˆ—è¡¨ï¼ˆæŒ‰å¤§å°æ’åºï¼‰
    recommended_models = [
        "qwen2.5:14b-instruct",  # ~8.6GB
        "qwen2.5-coder:14b",     # ~8.6GB
        "gpt-oss:20b-cloud",     # äº‘ç«¯20B
        "all-minilm:latest"      # ~44MB (å¤ªå°ï¼Œä»…æµ‹è¯•ç”¨)
    ]

    print("ğŸ” æ³•å¾‹çŸ¥è¯†å¤§æ¨¡å‹æµ‹è¯•å·¥å…·")
    print("="*60)

    # æ£€æŸ¥æ¨èæ¨¡å‹çš„å¯ç”¨æ€§
    print("ğŸ“‹ æ£€æŸ¥æ¨èæ¨¡å‹:")
    available_model = None

    for model in recommended_models:
        info = get_model_info(model)
        if info.get('available'):
            size_info = f"({info.get('size_gb', 0):.1f}GB)" if info.get('size_gb') > 0 else "(äº‘ç«¯)"
            print(f"âœ… {model} {size_info}")
            if not available_model and model != "all-minilm:latest":  # ä¸é€‰æ‹©å¤ªå°çš„æ¨¡å‹
                available_model = model
        else:
            print(f"âŒ {model} - ä¸å¯ç”¨")

    if available_model:
        print(f"\nğŸ¯ é€‰æ‹©æ¨¡å‹: {available_model}")
        score, max_score = test_legal_knowledge_ollama(available_model)
    else:
        print("\nâŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨èæ¨¡å‹ï¼Œè¯·æ£€æŸ¥OllamaæœåŠ¡")
        print("ğŸ’¡ æç¤º: è¿è¡Œ 'ollama serve' å¯åŠ¨æœåŠ¡")
        print("ğŸ’¡ æç¤º: è¿è¡Œ 'ollama pull qwen2.5:14b-instruct' ä¸‹è½½æ¨¡å‹")